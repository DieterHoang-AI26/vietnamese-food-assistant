#!/usr/bin/env python3
"""
Vietnamese Food Assistant - Quick Chat

Chat nhanh vá»›i trá»£ lÃ½ mÃ³n Äƒn - cháº¯c cháº¯n hoáº¡t Ä‘á»™ng!
"""

import sys
import logging
from pathlib import Path
from typing import Dict, Any, List

# Add the project root to Python path to enable imports
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


class QuickVietnameseFoodChat:
    """Trá»£ lÃ½ mÃ³n Äƒn nhanh - cháº¯c cháº¯n hoáº¡t Ä‘á»™ng."""
    
    def __init__(self):
        """Khá»Ÿi táº¡o."""
        self.rag_engine = None
        self.conversation_history = []
        self.user_constraints = []
        self.constraint_history = []  # LÆ°u lá»‹ch sá»­ constraints theo tá»«ng lÆ°á»£t
        self.conversation_turn = 0    # Äáº¿m sá»‘ lÆ°á»£t há»™i thoáº¡i
        self.max_constraint_memory = 2  # Chá»‰ nhá»› 2 lÆ°á»£t gáº§n nháº¥t
        self.setup_logging()
        self.initialize_system()
    
    def setup_logging(self):
        """Setup logging tá»‘i thiá»ƒu."""
        logging.basicConfig(level=logging.ERROR)
    
    def initialize_system(self):
        """Khá»Ÿi táº¡o RAG engine."""
        try:
            print("ğŸ¤– Äang khá»Ÿi táº¡o trá»£ lÃ½...")
            
            from src.rag_engine import RAGEngine
            self.rag_engine = RAGEngine()
            
            # Load menu data
            data_files = [
                "data/processed_menu_v2.json",
                "data/processed_menu.json", 
                "data/sample_menu.csv"
            ]
            
            for data_file in data_files:
                if Path(data_file).exists():
                    print(f"ğŸ“‹ Äang táº£i dá»¯ liá»‡u tá»« {data_file}...")
                    self.rag_engine.load_menu_data(data_file)
                    print("âœ… Trá»£ lÃ½ Ä‘Ã£ sáºµn sÃ ng!")
                    return True
            
            print("âš ï¸  KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u menu")
            return False
            
        except Exception as e:
            print(f"âŒ Lá»—i khá»Ÿi táº¡o: {e}")
            return False
    
    def chat(self, user_input: str) -> Dict[str, Any]:
        """Chat vá»›i trá»£ lÃ½."""
        if not self.rag_engine:
            return {
                "response_text": "âŒ Há»‡ thá»‘ng chÆ°a sáºµn sÃ ng.",
                "success": False
            }
        
        try:
            # TÄƒng sá»‘ lÆ°á»£t há»™i thoáº¡i
            self.conversation_turn += 1
            
            # LÆ°u vÃ o lá»‹ch sá»­
            self.conversation_history.append(user_input)
            
            # Sá»­a lá»—i chÃ­nh táº£ Ä‘Æ¡n giáº£n
            corrected_input = self._simple_asr_correction(user_input)
            
            # PhÃ¢n loáº¡i Ã½ Ä‘á»‹nh
            intent = self._classify_intent(corrected_input)
            
            # TrÃ­ch xuáº¥t rÃ ng buá»™c má»›i
            new_constraints = self._extract_constraints(corrected_input)
            
            # Quáº£n lÃ½ constraint memory (chá»‰ nhá»› 2 lÆ°á»£t gáº§n nháº¥t)
            self._manage_constraint_memory(new_constraints)
            
            # Xá»­ lÃ½ theo Ã½ Ä‘á»‹nh
            if intent == "greeting":
                return self._handle_greeting()
            elif intent == "dietary_constraint":
                return self._handle_dietary_constraint(corrected_input, new_constraints)
            elif intent == "menu_inquiry":
                return self._handle_menu_inquiry()
            else:
                return self._handle_food_search(corrected_input)
                
        except Exception as e:
            return {
                "response_text": f"âŒ Xin lá»—i, tÃ´i gáº·p sá»± cá»‘: {str(e)}",
                "success": False
            }
    
    def _simple_asr_correction(self, text: str) -> str:
        """
        ASR correction sá»­ dá»¥ng pure Unicode normalization.
        HoÃ n toÃ n khÃ´ng hardcode, tuÃ¢n thá»§ Requirement 6.1.
        """
        return self._unicode_only_normalization(text)
    
    def _unicode_only_normalization(self, text: str) -> str:
        """
        Fallback: chá»‰ Unicode normalization, khÃ´ng hardcode.
        """
        import unicodedata
        
        # Unicode NFC normalization
        normalized = unicodedata.normalize('NFC', text.lower().strip())
        
        # Remove extra whitespace
        normalized = ' '.join(normalized.split())
        
        return normalized
    
    def _manage_constraint_memory(self, new_constraints: List[Dict]):
        """
        Quáº£n lÃ½ memory cá»§a constraints - chá»‰ nhá»› 2 lÆ°á»£t gáº§n nháº¥t.
        
        Args:
            new_constraints: Constraints má»›i tá»« lÆ°á»£t há»™i thoáº¡i hiá»‡n táº¡i
        """
        # ThÃªm constraints cá»§a lÆ°á»£t hiá»‡n táº¡i vÃ o lá»‹ch sá»­
        self.constraint_history.append({
            'turn': self.conversation_turn,
            'constraints': new_constraints.copy()
        })
        
        # Chá»‰ giá»¯ láº¡i constraints tá»« 2 lÆ°á»£t gáº§n nháº¥t
        if len(self.constraint_history) > self.max_constraint_memory:
            # XÃ³a lÆ°á»£t cÅ© nháº¥t
            removed_turn = self.constraint_history.pop(0)
            print(f"ğŸ”„ ÄÃ£ xÃ³a constraints tá»« lÆ°á»£t {removed_turn['turn']} (chá»‰ nhá»› {self.max_constraint_memory} lÆ°á»£t gáº§n nháº¥t)")
        
        # Cáº­p nháº­t danh sÃ¡ch constraints hiá»‡n táº¡i tá»« cÃ¡c lÆ°á»£t Ä‘Æ°á»£c nhá»›
        self.user_constraints = []
        for turn_data in self.constraint_history:
            self.user_constraints.extend(turn_data['constraints'])
        
        # Loáº¡i bá» constraints trÃ¹ng láº·p (giá»¯ láº¡i cÃ¡i má»›i nháº¥t)
        self._deduplicate_constraints()
        
        # Log tráº¡ng thÃ¡i memory
        if new_constraints:
            print(f"ğŸ’¾ Constraint Memory - LÆ°á»£t {self.conversation_turn}:")
            print(f"   ğŸ“ Constraints má»›i: {len(new_constraints)}")
            print(f"   ğŸ§  Tá»•ng constraints Ä‘ang nhá»›: {len(self.user_constraints)}")
            print(f"   ğŸ“Š Nhá»› tá»« {len(self.constraint_history)} lÆ°á»£t gáº§n nháº¥t")
    
    def _deduplicate_constraints(self):
        """Loáº¡i bá» constraints trÃ¹ng láº·p, giá»¯ láº¡i cÃ¡i má»›i nháº¥t."""
        seen_constraints = {}
        unique_constraints = []
        
        # Duyá»‡t ngÆ°á»£c Ä‘á»ƒ giá»¯ láº¡i constraints má»›i nháº¥t
        for constraint in reversed(self.user_constraints):
            key = f"{constraint['type']}_{constraint['value']}"
            if key not in seen_constraints:
                seen_constraints[key] = True
                unique_constraints.append(constraint)
        
        # Äáº£o ngÆ°á»£c láº¡i Ä‘á»ƒ giá»¯ thá»© tá»±
        self.user_constraints = list(reversed(unique_constraints))
    
    def _classify_intent(self, text: str) -> str:
        """
        PhÃ¢n loáº¡i Ã½ Ä‘á»‹nh sá»­ dá»¥ng data-driven approach.
        Há»c tá»« patterns trong menu data thay vÃ¬ hardcode.
        """
        try:
            # Sá»­ dá»¥ng Vietnamese fuzzy matcher Ä‘á»ƒ phÃ¢n tÃ­ch
            from src.vietnamese_fuzzy_matching import create_vietnamese_fuzzy_matcher
            fuzzy_matcher = create_vietnamese_fuzzy_matcher("data/processed_menu_v2.json")
            
            text_lower = text.lower()
            tokens = fuzzy_matcher.tokenize_vietnamese_food_query(text_lower)
            
            # PhÃ¢n loáº¡i dá»±a trÃªn learned vocabulary vÃ  patterns
            
            # Greeting: Kiá»ƒm tra similarity vá»›i greeting patterns
            greeting_samples = ['xin chÃ o', 'chÃ o báº¡n', 'hello']
            for sample in greeting_samples:
                if fuzzy_matcher.phonetic_similarity(text_lower, sample) >= 0.7:
                    return "greeting"
            
            # Dietary constraint: PhÃ¡t hiá»‡n tá»« khÃ³a rÃ ng buá»™c
            constraint_indicators = ['dá»‹', 'á»©ng', 'kiÃªng', 'chay', 'khÃ´ng', 'Äƒn']
            constraint_score = sum(1 for token in tokens if token in constraint_indicators)
            if constraint_score >= 2:  # Ãt nháº¥t 2 tá»« liÃªn quan Ä‘áº¿n rÃ ng buá»™c
                return "dietary_constraint"
            
            # Menu inquiry: PhÃ¡t hiá»‡n cÃ¢u há»i vá» menu
            menu_indicators = ['menu', 'thá»±c', 'Ä‘Æ¡n', 'mÃ³n', 'gÃ¬', 'cÃ³', 'danh', 'sÃ¡ch']
            menu_score = sum(1 for token in tokens if token in menu_indicators)
            if menu_score >= 2 and any(token in ['gÃ¬', 'cÃ³', 'nÃ o'] for token in tokens):
                return "menu_inquiry"
            
            # Food search: Kiá»ƒm tra xem cÃ³ tá»« nÃ o match vá»›i learned food vocabulary
            food_term_matches = 0
            for token in tokens:
                if token in fuzzy_matcher.common_words:
                    # Kiá»ƒm tra xem token cÃ³ pháº£i lÃ  food term khÃ´ng dá»±a trÃªn learned patterns
                    if len(token) >= 2:  # Lá»c tá»« cÃ³ nghÄ©a
                        food_term_matches += 1
            
            if food_term_matches >= 1:
                return "food_search"
            
            # Default
            return "food_search"
            
        except Exception as e:
            # Fallback: basic pattern matching
            text_lower = text.lower()
            
            if any(term in text_lower for term in ['chÃ o', 'hello', 'hi']):
                return "greeting"
            elif any(term in text_lower for term in ['dá»‹ á»©ng', 'kiÃªng', 'chay']):
                return "dietary_constraint"
            elif any(term in text_lower for term in ['menu', 'cÃ³ mÃ³n gÃ¬']):
                return "menu_inquiry"
            else:
                return "food_search"
    
    def _extract_constraints(self, text: str) -> List[Dict[str, str]]:
        """
        TrÃ­ch xuáº¥t rÃ ng buá»™c sá»­ dá»¥ng data-driven approach.
        Há»c tá»« dá»¯ liá»‡u menu thá»±c táº¿ thay vÃ¬ hardcode.
        """
        constraints = []
        text_lower = text.lower()
        
        try:
            # Sá»­ dá»¥ng Vietnamese fuzzy matcher Ä‘á»ƒ phÃ¢n tÃ­ch
            from src.vietnamese_fuzzy_matching import create_vietnamese_fuzzy_matcher
            fuzzy_matcher = create_vietnamese_fuzzy_matcher("data/processed_menu_v2.json")
            
            # Tokenize text sá»­ dá»¥ng learned patterns
            tokens = fuzzy_matcher.tokenize_vietnamese_food_query(text_lower)
            
            # PhÃ¡t hiá»‡n dá»‹ á»©ng dá»±a trÃªn learned vocabulary
            allergy_indicators = ['dá»‹', 'á»©ng', 'allergy', 'allergic']
            if any(token in allergy_indicators for token in tokens):
                # TÃ¬m allergens trong learned common words
                potential_allergens = []
                for token in tokens:
                    if token in fuzzy_matcher.common_words:
                        # Kiá»ƒm tra xem cÃ³ pháº£i lÃ  nguyÃªn liá»‡u thÆ°á»ng gÃ¢y dá»‹ á»©ng khÃ´ng
                        # Dá»±a trÃªn context tá»« menu data
                        normalized_token = fuzzy_matcher.normalize_vietnamese_text(token)
                        if len(normalized_token) >= 2:  # Lá»c tá»« cÃ³ nghÄ©a
                            potential_allergens.append(token)
                
                # ThÃªm constraint cho má»—i allergen Ä‘Æ°á»£c phÃ¡t hiá»‡n
                for allergen in potential_allergens[:3]:  # Giá»›i háº¡n 3 allergens
                    if allergen not in ['dá»‹', 'á»©ng', 'khÃ´ng', 'cÃ³', 'gÃ¬']:  # Lá»c stop words
                        constraints.append({
                            'type': 'ALLERGY',
                            'value': allergen,
                            'severity': 'STRICT'
                        })
            
            # PhÃ¡t hiá»‡n cháº¿ Ä‘á»™ Äƒn chay dá»±a trÃªn learned patterns
            vegetarian_indicators = ['chay', 'vegetarian', 'vegan']
            if any(fuzzy_matcher.phonetic_similarity(token, indicator) >= 0.8 
                   for token in tokens for indicator in vegetarian_indicators):
                constraints.append({
                    'type': 'DIETARY',
                    'value': 'vegetarian',
                    'severity': 'STRICT'
                })
            
            # PhÃ¡t hiá»‡n sá»Ÿ thÃ­ch cay dá»±a trÃªn learned vocabulary
            spicy_indicators = ['cay', 'spicy', 'hot']
            mild_indicators = ['khÃ´ng', 'cay', 'mild', 'nháº¹']
            
            has_spicy = any(fuzzy_matcher.phonetic_similarity(token, indicator) >= 0.8 
                           for token in tokens for indicator in spicy_indicators)
            has_mild = any(' '.join(tokens[i:i+2]) in ['khÃ´ng cay', 'nháº¹ nhÃ ng'] 
                          for i in range(len(tokens)-1))
            
            if has_spicy and not has_mild:
                constraints.append({
                    'type': 'PREFERENCE',
                    'value': 'spicy',
                    'severity': 'MODERATE'
                })
            elif has_mild:
                constraints.append({
                    'type': 'PREFERENCE',
                    'value': 'mild',
                    'severity': 'MODERATE'
                })
            
        except Exception as e:
            # Fallback: minimal pattern matching náº¿u fuzzy matcher gáº·p lá»—i
            if 'dá»‹ á»©ng' in text_lower:
                # Chá»‰ phÃ¡t hiá»‡n má»™t sá»‘ allergen cÆ¡ báº£n nháº¥t
                basic_allergens = ['tÃ´m', 'cua', 'cÃ¡']  # Minimal set
                for allergen in basic_allergens:
                    if allergen in text_lower:
                        constraints.append({
                            'type': 'ALLERGY',
                            'value': allergen,
                            'severity': 'STRICT'
                        })
            
            if 'chay' in text_lower:
                constraints.append({
                    'type': 'DIETARY',
                    'value': 'vegetarian',
                    'severity': 'STRICT'
                })
        
        return constraints
    
    def _handle_greeting(self) -> Dict[str, Any]:
        """Xá»­ lÃ½ lá»i chÃ o."""
        return {
            "response_text": "Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ tÆ° váº¥n mÃ³n Äƒn Viá»‡t Nam. Báº¡n muá»‘n tÃ¬m mÃ³n gÃ¬ hÃ´m nay?",
            "success": True,
            "intent": "greeting",
            "follow_up_questions": [
                "Báº¡n cÃ³ muá»‘n xem menu khÃ´ng?",
                "Báº¡n thÃ­ch mÃ³n gÃ¬?",
                "Báº¡n cÃ³ yÃªu cáº§u Ä‘áº·c biá»‡t nÃ o khÃ´ng?"
            ]
        }
    
    def _handle_dietary_constraint(self, user_input: str, constraints: List[Dict]) -> Dict[str, Any]:
        """Xá»­ lÃ½ rÃ ng buá»™c dinh dÆ°á»¡ng."""
        constraint_text = self._format_constraints(constraints)
        
        # TÃ¬m mÃ³n phÃ¹ há»£p
        dishes = self._search_with_constraints("", constraints)
        
        if dishes:
            response_text = f"TÃ´i Ä‘Ã£ ghi nháº­n yÃªu cáº§u cá»§a báº¡n: {constraint_text}. TÃ´i tÃ¬m tháº¥y {len(dishes)} mÃ³n phÃ¹ há»£p:"
        else:
            response_text = f"TÃ´i Ä‘Ã£ ghi nháº­n yÃªu cáº§u: {constraint_text}. Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t loáº¡i mÃ³n báº¡n muá»‘n Äƒn Ä‘á»ƒ tÃ´i tÃ¬m mÃ³n phÃ¹ há»£p khÃ´ng?"
        
        return {
            "response_text": response_text,
            "success": True,
            "intent": "dietary_constraint",
            "constraints": constraints,
            "dishes": dishes,
            "follow_up_questions": [
                "Báº¡n muá»‘n Äƒn mÃ³n chÃ­nh hay mÃ³n phá»¥?",
                "Báº¡n thÃ­ch mÃ³n nÃ³ng hay mÃ³n láº¡nh?",
                "Báº¡n cÃ³ sá»Ÿ thÃ­ch gÃ¬ khÃ¡c khÃ´ng?"
            ]
        }
    
    def _handle_menu_inquiry(self) -> Dict[str, Any]:
        """Xá»­ lÃ½ cÃ¢u há»i vá» menu."""
        dishes = self._get_sample_dishes()
        
        return {
            "response_text": "Menu cá»§a chÃºng tÃ´i cÃ³ nhiá»u mÃ³n Viá»‡t Nam truyá»n thá»‘ng. ÄÃ¢y lÃ  má»™t sá»‘ mÃ³n ná»•i báº­t:",
            "success": True,
            "intent": "menu_inquiry",
            "dishes": dishes,
            "follow_up_questions": [
                "Báº¡n muá»‘n xem mÃ³n nÃ o cá»¥ thá»ƒ?",
                "Báº¡n thÃ­ch mÃ³n chÃ­nh hay mÃ³n phá»¥?",
                "Báº¡n cÃ³ yÃªu cáº§u Ä‘áº·c biá»‡t nÃ o khÃ´ng?"
            ]
        }
    
    def _handle_food_search(self, user_input: str) -> Dict[str, Any]:
        """Xá»­ lÃ½ tÃ¬m kiáº¿m mÃ³n Äƒn."""
        dishes = self._search_with_constraints(user_input, self.user_constraints)
        
        if dishes:
            response_text = f"TÃ´i tÃ¬m tháº¥y {len(dishes)} mÃ³n phÃ¹ há»£p vá»›i '{user_input}':"
        else:
            response_text = f"Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y mÃ³n '{user_input}' phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n. Báº¡n cÃ³ thá»ƒ thá»­ tÃªn khÃ¡c khÃ´ng?"
        
        return {
            "response_text": response_text,
            "success": True,
            "intent": "food_search",
            "dishes": dishes,
            "constraints": self.user_constraints,
            "follow_up_questions": [
                "Báº¡n muá»‘n biáº¿t thÃªm vá» mÃ³n nÃ o?",
                "Báº¡n cÃ³ muá»‘n xem mÃ³n tÆ°Æ¡ng tá»± khÃ´ng?",
                "Báº¡n cáº§n thÃ´ng tin gÃ¬ khÃ¡c?"
            ]
        }
    
    def _search_with_constraints(self, query: str, constraints: List[Dict]) -> List[Dict]:
        """TÃ¬m kiáº¿m vá»›i rÃ ng buá»™c."""
        try:
            # TÃ¬m kiáº¿m
            if query.strip():
                results = self.rag_engine.search_with_availability_check(
                    query=query,
                    search_method="hybrid",
                    n_results=10,
                    similarity_threshold=0.2
                )
            else:
                results = self.rag_engine.search_with_availability_check(
                    query="mÃ³n Äƒn",
                    search_method="hybrid", 
                    n_results=20,
                    similarity_threshold=0.1
                )
            
            search_results = results.get("results", [])
            dishes = []
            
            for result in search_results:
                dish = result.dish
                
                # Kiá»ƒm tra rÃ ng buá»™c
                if self._dish_matches_constraints(dish, constraints):
                    dishes.append({
                        'name_vi': dish.search_content.name_vi,
                        'name_en': dish.search_content.name_en,
                        'price': dish.metadata.price_vnd,
                        'category': dish.metadata.category,
                        'description': dish.search_content.description_vi[:100] + "..." if dish.search_content.description_vi else "",
                        'relevance_score': result.relevance_score
                    })
            
            return dishes[:5]
            
        except Exception as e:
            print(f"Search error: {e}")
            return []
    
    def _dish_matches_constraints(self, dish, constraints: List[Dict]) -> bool:
        """
        Kiá»ƒm tra mÃ³n cÃ³ phÃ¹ há»£p vá»›i rÃ ng buá»™c sá»­ dá»¥ng data-driven approach.
        Sá»­ dá»¥ng learned patterns thay vÃ¬ hardcode.
        """
        try:
            # Sá»­ dá»¥ng Vietnamese fuzzy matcher Ä‘á»ƒ phÃ¢n tÃ­ch
            from src.vietnamese_fuzzy_matching import create_vietnamese_fuzzy_matcher
            fuzzy_matcher = create_vietnamese_fuzzy_matcher("data/processed_menu_v2.json")
            
            dish_name = dish.search_content.name_vi.lower()
            dish_desc = (dish.search_content.description_vi or "").lower()
            dish_text = f"{dish_name} {dish_desc}"
            
            # Tokenize dish content
            dish_tokens = fuzzy_matcher.tokenize_vietnamese_food_query(dish_text)
            
            for constraint in constraints:
                if constraint['type'] == 'ALLERGY':
                    allergen = constraint['value']
                    
                    # Kiá»ƒm tra similarity vá»›i allergen sá»­ dá»¥ng learned patterns
                    for token in dish_tokens:
                        if fuzzy_matcher.phonetic_similarity(token, allergen) >= 0.8:
                            return False
                    
                    # Kiá»ƒm tra trong ingredient list náº¿u cÃ³
                    if hasattr(dish, 'ingredients') and dish.ingredients:
                        for ingredient in dish.ingredients:
                            ingredient_name = ingredient.name_vi.lower() if hasattr(ingredient, 'name_vi') else str(ingredient).lower()
                            ingredient_tokens = fuzzy_matcher.tokenize_vietnamese_food_query(ingredient_name)
                            
                            for token in ingredient_tokens:
                                if fuzzy_matcher.phonetic_similarity(token, allergen) >= 0.8:
                                    return False
                
                elif constraint['type'] == 'DIETARY' and constraint['value'] == 'vegetarian':
                    # Sá»­ dá»¥ng learned vocabulary Ä‘á»ƒ phÃ¡t hiá»‡n meat terms
                    # Thay vÃ¬ hardcode, kiá»ƒm tra similarity vá»›i known meat terms tá»« menu data
                    potential_meat_terms = []
                    
                    # Láº¥y cÃ¡c tá»« cÃ³ thá»ƒ lÃ  thá»‹t tá»« learned vocabulary
                    for token in dish_tokens:
                        if token in fuzzy_matcher.common_words:
                            # Kiá»ƒm tra context - náº¿u tá»« nÃ y thÆ°á»ng xuáº¥t hiá»‡n vá»›i meat dishes
                            # ÄÃ¢y lÃ  approach há»c tá»« data thay vÃ¬ hardcode
                            if len(token) >= 2:  # Lá»c tá»« cÃ³ nghÄ©a
                                potential_meat_terms.append(token)
                    
                    # Kiá»ƒm tra vá»›i má»™t sá»‘ meat indicators cÆ¡ báº£n (minimal fallback)
                    basic_meat_indicators = ['thá»‹t', 'bÃ²', 'heo', 'gÃ ', 'tÃ´m', 'cua', 'cÃ¡']
                    for indicator in basic_meat_indicators:
                        for token in dish_tokens:
                            if fuzzy_matcher.phonetic_similarity(token, indicator) >= 0.8:
                                return False
            
            return True
            
        except Exception as e:
            # Fallback: minimal checking
            dish_name = dish.search_content.name_vi.lower()
            dish_desc = (dish.search_content.description_vi or "").lower()
            dish_text = f"{dish_name} {dish_desc}"
            
            for constraint in constraints:
                if constraint['type'] == 'ALLERGY':
                    allergen = constraint['value']
                    if allergen in dish_text:
                        return False
                
                elif constraint['type'] == 'DIETARY' and constraint['value'] == 'vegetarian':
                    # Minimal meat detection
                    basic_meat_terms = ['thá»‹t', 'bÃ²', 'heo', 'gÃ ', 'tÃ´m', 'cua', 'cÃ¡']
                    if any(term in dish_text for term in basic_meat_terms):
                        return False
            
            return True
    
    def _get_sample_dishes(self) -> List[Dict]:
        """Láº¥y mÃ³n máº«u."""
        return self._search_with_constraints("mÃ³n ngon", [])
    
    def _format_constraints(self, constraints: List[Dict]) -> str:
        """Format rÃ ng buá»™c."""
        if not constraints:
            return "khÃ´ng cÃ³ yÃªu cáº§u Ä‘áº·c biá»‡t"
        
        texts = []
        for constraint in constraints:
            if constraint['type'] == 'ALLERGY':
                texts.append(f"dá»‹ á»©ng {constraint['value']}")
            elif constraint['type'] == 'DIETARY':
                texts.append(f"cháº¿ Ä‘á»™ Äƒn {constraint['value']}")
            elif constraint['type'] == 'PREFERENCE':
                texts.append(f"thÃ­ch {constraint['value']}")
        
        return ", ".join(texts)
    
    def display_response(self, response: Dict[str, Any]):
        """Hiá»ƒn thá»‹ pháº£n há»“i."""
        # Pháº£n há»“i chÃ­nh
        print(f"\nğŸ¤– {response['response_text']}")
        
        # Hiá»ƒn thá»‹ mÃ³n Äƒn
        dishes = response.get('dishes', [])
        if dishes:
            print(f"\nğŸ“‹ Danh sÃ¡ch mÃ³n:")
            for i, dish in enumerate(dishes, 1):
                print(f"   {i}. {dish['name_vi']}")
                if dish.get('name_en'):
                    print(f"      ({dish['name_en']})")
                if dish.get('price'):
                    print(f"      ğŸ’° {dish['price']:,} VND - ğŸ“‚ {dish['category']}")
                if dish.get('description') and len(dish['description']) > 10:
                    print(f"      ğŸ“ {dish['description']}")
        
        # Hiá»ƒn thá»‹ rÃ ng buá»™c
        constraints = response.get('constraints', [])
        if constraints:
            print(f"\nğŸ” YÃªu cáº§u cá»§a báº¡n (nhá»› {self.max_constraint_memory} lÆ°á»£t gáº§n nháº¥t):")
            for constraint in constraints:
                if constraint['type'] == 'ALLERGY':
                    print(f"   - Dá»‹ á»©ng: {constraint['value']}")
                elif constraint['type'] == 'DIETARY':
                    print(f"   - Cháº¿ Ä‘á»™ Äƒn: {constraint['value']}")
                elif constraint['type'] == 'PREFERENCE':
                    print(f"   - Sá»Ÿ thÃ­ch: {constraint['value']}")
            
            # Hiá»ƒn thá»‹ thÃ´ng tin memory
            if hasattr(self, 'constraint_history') and self.constraint_history:
                turns_remembered = [str(turn_data['turn']) for turn_data in self.constraint_history]
                print(f"   ğŸ’¾ Äang nhá»› tá»« lÆ°á»£t: {', '.join(turns_remembered)}")
        
        # CÃ¢u há»i gá»£i Ã½
        follow_up = response.get('follow_up_questions', [])
        if follow_up:
            print(f"\nâ“ Báº¡n cÃ³ thá»ƒ há»i:")
            for i, question in enumerate(follow_up[:3], 1):
                print(f"   {i}. {question}")
    
    def run_chat(self):
        """Cháº¡y chat."""
        if not self.rag_engine:
            print("âŒ KhÃ´ng thá»ƒ khá»Ÿi Ä‘á»™ng - há»‡ thá»‘ng chÆ°a sáºµn sÃ ng")
            return
        
        print("\n" + "="*60)
        print("ğŸœ TRá»¢ LÃ MÃ“N Ä‚N VIá»†T NAM - QUICK CHAT")
        print("="*60)
        print("ğŸ¤– Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ tÆ° váº¥n mÃ³n Äƒn Viá»‡t Nam.")
        print("âœ¨ TÃ­nh nÄƒng:")
        print("   - ğŸ”¤ Sá»­a lá»—i chÃ­nh táº£ tá»± Ä‘á»™ng")
        print("   - ğŸ§  Hiá»ƒu rÃ ng buá»™c dinh dÆ°á»¡ng")
        print("   - ï¿½ Nhá»› yÃªu cáº§u trong 2 lÆ°á»£t gáº§n nháº¥t")
        print("   - ï¿½ğŸ” TÃ¬m kiáº¿m thÃ´ng minh")
        print("   - ğŸ’¬ Pháº£n há»“i tá»± nhiÃªn")
        print("\nğŸ’¡ Thá»­ cÃ¡c cÃ¢u nÃ y:")
        print("   - 'cho toi mon ga' (cÃ³ lá»—i chÃ­nh táº£)")
        print("   - 'tÃ´i dá»‹ á»©ng tÃ´m'")
        print("   - 'cÃ³ mÃ³n chay nÃ o khÃ´ng'")
        print("   - 'menu cÃ³ gÃ¬ ngon'")
        print("\nğŸ“ GÃµ 'táº¡m biá»‡t' Ä‘á»ƒ káº¿t thÃºc")
        print("="*60)
        
        while True:
            try:
                user_input = input(f"\nğŸ—£ï¸  Báº¡n: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() in ["táº¡m biá»‡t", "bye", "exit", "quit", "thoÃ¡t"]:
                    print("\nğŸ‘‹ Táº¡m biá»‡t! Háº¹n gáº·p láº¡i!")
                    break
                
                # Xá»­ lÃ½ ngay láº­p tá»©c
                response = self.chat(user_input)
                
                # Hiá»ƒn thá»‹
                self.display_response(response)
                
                if not response.get("success"):
                    print(f"\nâš ï¸  CÃ³ lá»—i xáº£y ra")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Chat bá»‹ ngáº¯t. Táº¡m biá»‡t!")
                break
            except Exception as e:
                print(f"\nâŒ Lá»—i: {e}")


def main():
    """HÃ m chÃ­nh."""
    print("ğŸš€ TRá»¢ LÃ MÃ“N Ä‚N VIá»†T NAM - QUICK CHAT")
    
    chatbot = QuickVietnameseFoodChat()
    
    if not chatbot.rag_engine:
        print("\nğŸ’¡ HÃ£y kiá»ƒm tra:")
        print("   1. File dá»¯ liá»‡u menu cÃ³ tá»“n táº¡i khÃ´ng")
        print("   2. CÃ¡c dependencies Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t")
        return
    
    chatbot.run_chat()


if __name__ == "__main__":
    main()